{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V28"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0231bc74253642d9bbd1d48886efdec4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e033349c8b244f6ca8c0e3a7a148622c","IPY_MODEL_566080d5e93a4bd39f13550dc025410b","IPY_MODEL_789ced0a5f7b4cd79ed7c71bcff3ee7b"],"layout":"IPY_MODEL_a0c22217f30347fcb7a9ab88aed9905d"}},"e033349c8b244f6ca8c0e3a7a148622c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57cc677d8b2d486daa9aa173be6f1402","placeholder":"​","style":"IPY_MODEL_3328c7ee8b2b48c685b952be234e8049","value":"Loading checkpoint shards: 100%"}},"566080d5e93a4bd39f13550dc025410b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c641ddc7d3549879db5e2551baa6e7a","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_088042b421214b7782d7052d8c4dc955","value":2}},"789ced0a5f7b4cd79ed7c71bcff3ee7b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e23da6505ce640568d21c259ef46acd8","placeholder":"​","style":"IPY_MODEL_4dacb5592cd142c9b405d269113fe116","value":" 2/2 [00:04&lt;00:00,  1.88s/it]"}},"a0c22217f30347fcb7a9ab88aed9905d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57cc677d8b2d486daa9aa173be6f1402":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3328c7ee8b2b48c685b952be234e8049":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c641ddc7d3549879db5e2551baa6e7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"088042b421214b7782d7052d8c4dc955":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e23da6505ce640568d21c259ef46acd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4dacb5592cd142c9b405d269113fe116":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["# Installing the required libraries\n","# pip install speech_recognition\n","# pip install soundfile\n","# pip install opencv-python-headless\n","# pip install torch\n","# pip install transformers\n","# pip install huggingface_hub"],"metadata":{"id":"73nkiH3KDXQr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723348591557,"user_tz":-330,"elapsed":16014,"user":{"displayName":"Kumar Raju (Sri)","userId":"04898248165068786936"}},"outputId":"e8aaee4c-a545-4c9f-e356-8fda4532cf2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n","Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.7.24)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cpu)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: pyttsx3 in /usr/local/lib/python3.10/dist-packages (2.90)\n","Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.4)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.32.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.7.4)\n","Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.17.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.23.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.15.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.7.4)\n","Collecting opencv-python-headless\n","  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.26.4)\n","Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: opencv-python-headless\n","Successfully installed opencv-python-headless-4.10.0.84\n"]}]},{"cell_type":"code","source":["!apt install espeak\n","!apt-get install portaudio19-dev\n","!pip install pyaudio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Us44ghrlJRe","executionInfo":{"status":"ok","timestamp":1723348640630,"user_tz":-330,"elapsed":5384,"user":{"displayName":"Kumar Raju (Sri)","userId":"04898248165068786936"}},"outputId":"def3f57c-67f4-4a29-8b0e-18a432446ff6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","espeak is already the newest version (1.48.15+dfsg-3).\n","0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","portaudio19-dev is already the newest version (19.6.0-1.1).\n","0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n","Requirement already satisfied: pyaudio in /usr/local/lib/python3.10/dist-packages (0.2.14)\n"]}]},{"cell_type":"code","source":["# importing the libraries\n","\n","import speech_recognition as sr\n","import pyttsx3\n","import cv2\n","import torch\n","\n","from huggingface_hub import login\n","from transformers import WhisperProcessor, WhisperForConditionalGeneration, AutoTokenizer, AutoModelForCausalLM"],"metadata":{"id":"ysN9WHGwDXOv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hugging_face_token_id = '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'\n","login(hugging_face_token_id)\n","\n","\n","# loading the models  (Whisper for speech) (Llama 2 for text)\n","\n","whisper_processor = WhisperProcessor.from_pretrained(\"openai/whisper-base\")\n","whisper_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-base\")\n","\n","llama_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n","llama_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n","\n","tts_engine = pyttsx3.init()\n","recognizer = sr.Recognizer()"],"metadata":{"id":"pTfL77_8cIGg","colab":{"base_uri":"https://localhost:8080/","height":140,"referenced_widgets":["0231bc74253642d9bbd1d48886efdec4","e033349c8b244f6ca8c0e3a7a148622c","566080d5e93a4bd39f13550dc025410b","789ced0a5f7b4cd79ed7c71bcff3ee7b","a0c22217f30347fcb7a9ab88aed9905d","57cc677d8b2d486daa9aa173be6f1402","3328c7ee8b2b48c685b952be234e8049","6c641ddc7d3549879db5e2551baa6e7a","088042b421214b7782d7052d8c4dc955","e23da6505ce640568d21c259ef46acd8","4dacb5592cd142c9b405d269113fe116"]},"executionInfo":{"status":"ok","timestamp":1723348776166,"user_tz":-330,"elapsed":5332,"user":{"displayName":"Kumar Raju (Sri)","userId":"04898248165068786936"}},"outputId":"2d2ec6eb-8fc2-4388-ef9d-6ae59170ed33"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Token is valid (permission: fineGrained).\n","Your token has been saved in your configured git credential helpers (store).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0231bc74253642d9bbd1d48886efdec4"}},"metadata":{}}]},{"cell_type":"code","source":["def recognize_speech_microphone():  # recognize from microphone\n","    with sr.Microphone() as source:\n","        recognizer.adjust_for_ambient_noise(source)\n","        print(\"Listening...\")\n","        audio = recognizer.listen(source, timeout=5)\n","        audio_data = audio.get_wav_data()\n","        inputs = whisper_processor(audio_data, return_tensors=\"pt\", sampling_rate=16000)\n","        outputs = whisper_model.generate(inputs[\"input_ids\"])\n","        text = whisper_processor.decode(outputs[0], skip_special_tokens=True)\n","        print(f\"Recognized Text: {text}\")\n","        return text"],"metadata":{"id":"J-dDqturcIEk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def recognize_speech_webcam(): # recognize from webcam\n","    cap = cv2.VideoCapture(0)\n","\n","    while True:\n","        ret, frame = cap.read()\n","        if not ret:\n","            print(\"Failed to capture video.\")\n","            break\n","\n","        cv2.imshow(\"Webcam\", frame)\n","\n","        if cv2.waitKey(1) & 0xFF == ord('q'):\n","            with sr.Microphone() as source:\n","                print(\"Listening...\")\n","                audio = recognizer.listen(source, timeout=5)\n","                audio_data = audio.get_wav_data()\n","                inputs = whisper_processor(audio_data, return_tensors=\"pt\", sampling_rate=16000)\n","                outputs = whisper_model.generate(inputs[\"input_ids\"])\n","                text = whisper_processor.decode(outputs[0], skip_special_tokens=True)\n","                print(f\"Recognized Text: {text}\")\n","                cap.release()\n","                cv2.destroyAllWindows()\n","                return text\n","\n","    cap.release()\n","    cv2.destroyAllWindows()"],"metadata":{"id":"UboZ0BmKkWB7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def recognize_speech_text_input(): # recognize from text\n","    text = input(\"Enter your text: \")\n","    return text"],"metadata":{"id":"bJ7-OvZjkV-j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_response(input_text):\n","    inputs = llama_tokenizer(input_text, return_tensors=\"pt\")\n","    outputs = llama_model.generate(inputs[\"input_ids\"])\n","    response_text = llama_tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    print(f\"Generated Response: {response_text}\")\n","    return response_text"],"metadata":{"id":"YjF5lmGpkV79"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def speak_text(text):\n","    tts_engine.say(text)\n","    tts_engine.runAndWait()"],"metadata":{"id":"5uYOfKi8kV5n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def main():   # main loop for full code\n","    print(\"Select input method:\")\n","    print(\"1: Microphone\")\n","    print(\"2: Webcam\")\n","    print(\"3: Text Input\")\n","\n","    choice = input(\"Enter the number of your choice: \")\n","\n","    if choice == \"1\":\n","        recognize_speech = recognize_speech_microphone\n","    elif choice == \"2\":\n","        recognize_speech = recognize_speech_webcam\n","    elif choice == \"3\":\n","        recognize_speech = recognize_speech_text_input\n","    else:\n","        print(\"Invalid choice!\")\n","        return\n","\n","    print(\"Starting the speech-to-speech application...\")\n","\n","    while True:\n","        spoken_text = recognize_speech()\n","        if not spoken_text:\n","            continue\n","\n","        response_text = generate_response(spoken_text)\n","        speak_text(response_text)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":847},"id":"9op5arX5kV29","executionInfo":{"status":"error","timestamp":1723349541401,"user_tz":-330,"elapsed":731495,"user":{"displayName":"Kumar Raju (Sri)","userId":"04898248165068786936"}},"outputId":"5405af24-1ad0-4ee0-f7f3-3a7bc516d78d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Select input method:\n","1: Microphone\n","2: Webcam\n","3: Text Input\n","Enter the number of your choice: 3\n","Starting the speech-to-speech application...\n","Enter your text: where is tajmahal?\n","Generated Response: where is tajmahal?\n","\n","The Taj Mahal is located in Agra, India. It is situated on the southern bank of the Yamuna River, and is considered one of the most beautiful examples of Mughal architecture in India. The Taj Mahal was built in the 17th century by Mughal Emperor Shah Jahan as a mausoleum for his wife, Mumtaz Mahal, who died during childbirth in 1631. The monument is made of white marble and features intricate inlay work of precious stones, including jasper, jade, and turquoise. It is considered one of the Seven Wonders of the World and is a UNESCO World Heritage Site.\n","Enter your text: IT means\n","Generated Response: IT means Information Technology. IT is a broad field that combines computer science, computer engineering, and other areas to design, develop, and manage computer systems and technology. IT professionals work in a variety of settings, including businesses, government agencies, and educational institutions, and may specialize in areas such as software development, network administration, cybersecurity, data analytics, and more.\n","\n","Some common job roles in IT include:\n","\n","1. Software Developer: Designs, develops, and tests software programs using various programming languages and technologies.\n","2. Network Administrator: Installs, maintains, and troubleshoots computer networks, including local area networks (LANs), wide area networks (WANs), and the Internet.\n","3. Cybersecurity Specialist: Protects computer systems and networks from cyber threats by implementing security measures, monitoring systems for potential breaches, and responding to incidents.\n","4. Data Analyst: Collects, organizes, and analyzes data to help organizations make informed decisions.\n","5. IT Project Manager: Oversees the planning, execution, and delivery of IT projects, ensuring they are completed on time, within budget, and to the satisfaction of stakeholders.\n","6. Technical Support Specialist: Provides assistance and support to users of computer systems and technology, troubleshooting problems and answering questions to help them get back to work.\n","7. Database Administrator: Designs, implements, and maintains databases for organizations, ensuring they are secure, efficient, and scalable.\n","8. Artificial Intelligence/Machine Learning Engineer: Develops and implements artificial intelligence and machine learning solutions for organizations, including natural language processing, computer vision, and predictive analytics.\n","9. Cloud Computing Engineer: Designs, builds, and manages cloud computing systems for organizations, including infrastructure as a service (IaaS), platform as a service (PaaS), and software as a service (SaaS).\n","10. IT Consultant: Provides advice and guidance to organizations on how to best use technology to achieve their business goals, including evaluating existing systems, identifying areas for improvement, and implementing new technologies.\n","\n","These are just a few examples of the many job roles available in IT. As technology continues to evolve and advance, new job roles and specialties are emerging all the time.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"Interrupted by user","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-45cf59f2fafd>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-25-45cf59f2fafd>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Step 1: Capture and recognize speech\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mspoken_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecognize_speech\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mspoken_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-a4db62a83519>\u001b[0m in \u001b[0;36mrecognize_speech_text_input\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Step 7: Define the function for text input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecognize_speech_text_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your text: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}]},{"cell_type":"code","source":[],"metadata":{"id":"HEc8T6qnkV0x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"R8UjkCRycICT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bKbD2_4HcIAE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Ngy3Ia8ccH93"},"execution_count":null,"outputs":[]}]}