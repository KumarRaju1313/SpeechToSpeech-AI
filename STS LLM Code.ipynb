{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V28"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0231bc74253642d9bbd1d48886efdec4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e033349c8b244f6ca8c0e3a7a148622c","IPY_MODEL_566080d5e93a4bd39f13550dc025410b","IPY_MODEL_789ced0a5f7b4cd79ed7c71bcff3ee7b"],"layout":"IPY_MODEL_a0c22217f30347fcb7a9ab88aed9905d"}},"e033349c8b244f6ca8c0e3a7a148622c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57cc677d8b2d486daa9aa173be6f1402","placeholder":"​","style":"IPY_MODEL_3328c7ee8b2b48c685b952be234e8049","value":"Loading checkpoint shards: 100%"}},"566080d5e93a4bd39f13550dc025410b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c641ddc7d3549879db5e2551baa6e7a","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_088042b421214b7782d7052d8c4dc955","value":2}},"789ced0a5f7b4cd79ed7c71bcff3ee7b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e23da6505ce640568d21c259ef46acd8","placeholder":"​","style":"IPY_MODEL_4dacb5592cd142c9b405d269113fe116","value":" 2/2 [00:04&lt;00:00,  1.88s/it]"}},"a0c22217f30347fcb7a9ab88aed9905d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57cc677d8b2d486daa9aa173be6f1402":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3328c7ee8b2b48c685b952be234e8049":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c641ddc7d3549879db5e2551baa6e7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"088042b421214b7782d7052d8c4dc955":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e23da6505ce640568d21c259ef46acd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4dacb5592cd142c9b405d269113fe116":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install SpeechRecognition\n","!pip install soundfile\n","!pip install opencv-python-headless\n","!pip install torch\n","!pip install transformers\n","!pip install huggingface_hub"],"metadata":{"id":"73nkiH3KDXQr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3b4cabea-fb7f-462e-f34a-ab6f8f3becb6","executionInfo":{"status":"ok","timestamp":1729419475356,"user_tz":-330,"elapsed":10494,"user":{"displayName":"Kumar Raju (Sri)","userId":"04898248165068786936"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting SpeechRecognition\n","  Downloading SpeechRecognition-3.11.0-py2.py3-none-any.whl.metadata (28 kB)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.32.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.8.30)\n","Downloading SpeechRecognition-3.11.0-py2.py3-none-any.whl (32.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: SpeechRecognition\n","Successfully installed SpeechRecognition-3.11.0\n","Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.26.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cpu)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.9.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n"]}]},{"cell_type":"code","source":["!apt install espeak\n","!apt-get install portaudio19-dev\n","!pip install pyaudio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Us44ghrlJRe","outputId":"de14e8df-62c8-4f3d-eaf2-515986960ea4","executionInfo":{"status":"ok","timestamp":1729418028316,"user_tz":-330,"elapsed":26125,"user":{"displayName":"Kumar Raju (Sri)","userId":"04898248165068786936"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  espeak-data libespeak1 libportaudio2 libsonic0\n","The following NEW packages will be installed:\n","  espeak espeak-data libespeak1 libportaudio2 libsonic0\n","0 upgraded, 5 newly installed, 0 to remove and 0 not upgraded.\n","Need to get 1,382 kB of archives.\n","After this operation, 3,178 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsonic0 amd64 0.2.0-11build1 [10.3 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 espeak-data amd64 1.48.15+dfsg-3 [1,085 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libespeak1 amd64 1.48.15+dfsg-3 [156 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 espeak amd64 1.48.15+dfsg-3 [64.2 kB]\n","Fetched 1,382 kB in 0s (3,895 kB/s)\n","Selecting previously unselected package libportaudio2:amd64.\n","(Reading database ... 119634 files and directories currently installed.)\n","Preparing to unpack .../libportaudio2_19.6.0-1.1_amd64.deb ...\n","Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n","Selecting previously unselected package libsonic0:amd64.\n","Preparing to unpack .../libsonic0_0.2.0-11build1_amd64.deb ...\n","Unpacking libsonic0:amd64 (0.2.0-11build1) ...\n","Selecting previously unselected package espeak-data:amd64.\n","Preparing to unpack .../espeak-data_1.48.15+dfsg-3_amd64.deb ...\n","Unpacking espeak-data:amd64 (1.48.15+dfsg-3) ...\n","Selecting previously unselected package libespeak1:amd64.\n","Preparing to unpack .../libespeak1_1.48.15+dfsg-3_amd64.deb ...\n","Unpacking libespeak1:amd64 (1.48.15+dfsg-3) ...\n","Selecting previously unselected package espeak.\n","Preparing to unpack .../espeak_1.48.15+dfsg-3_amd64.deb ...\n","Unpacking espeak (1.48.15+dfsg-3) ...\n","Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n","Setting up libsonic0:amd64 (0.2.0-11build1) ...\n","Setting up espeak-data:amd64 (1.48.15+dfsg-3) ...\n","Setting up libespeak1:amd64 (1.48.15+dfsg-3) ...\n","Setting up espeak (1.48.15+dfsg-3) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  libportaudiocpp0\n","Suggested packages:\n","  portaudio19-doc\n","The following NEW packages will be installed:\n","  libportaudiocpp0 portaudio19-dev\n","0 upgraded, 2 newly installed, 0 to remove and 0 not upgraded.\n","Need to get 122 kB of archives.\n","After this operation, 703 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudiocpp0 amd64 19.6.0-1.1 [16.1 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 portaudio19-dev amd64 19.6.0-1.1 [106 kB]\n","Fetched 122 kB in 0s (583 kB/s)\n","Selecting previously unselected package libportaudiocpp0:amd64.\n","(Reading database ... 119964 files and directories currently installed.)\n","Preparing to unpack .../libportaudiocpp0_19.6.0-1.1_amd64.deb ...\n","Unpacking libportaudiocpp0:amd64 (19.6.0-1.1) ...\n","Selecting previously unselected package portaudio19-dev:amd64.\n","Preparing to unpack .../portaudio19-dev_19.6.0-1.1_amd64.deb ...\n","Unpacking portaudio19-dev:amd64 (19.6.0-1.1) ...\n","Setting up libportaudiocpp0:amd64 (19.6.0-1.1) ...\n","Setting up portaudio19-dev:amd64 (19.6.0-1.1) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n","Collecting pyaudio\n","  Downloading PyAudio-0.2.14.tar.gz (47 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: pyaudio\n","  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyaudio: filename=PyAudio-0.2.14-cp310-cp310-linux_x86_64.whl size=63863 sha256=d28c19dc4b74f188a446c617bfbb5d3e00aa821cf810e5040158da1f3a1ae302\n","  Stored in directory: /root/.cache/pip/wheels/d6/21/f4/0b51d41ba79e51b16295cbb096ec49f334792814d545b508c5\n","Successfully built pyaudio\n","Installing collected packages: pyaudio\n","Successfully installed pyaudio-0.2.14\n"]}]},{"cell_type":"code","source":["# importing the libraries\n","\n","import SpeechRecognition as sr\n","import pyttsx3\n","import cv2\n","import torch\n","\n","from huggingface_hub import login\n","from transformers import WhisperProcessor, WhisperForConditionalGeneration, AutoTokenizer, AutoModelForCausalLM"],"metadata":{"id":"ysN9WHGwDXOv","colab":{"base_uri":"https://localhost:8080/","height":400},"executionInfo":{"status":"error","timestamp":1729419452225,"user_tz":-330,"elapsed":440,"user":{"displayName":"Kumar Raju (Sri)","userId":"04898248165068786936"}},"outputId":"b5c5f0d2-01b6-4076-b873-56f70867f1f9"},"execution_count":11,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'SpeechRecognition'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-2882f7ecbbb5>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# importing the libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mSpeechRecognition\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyttsx3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'SpeechRecognition'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["hugging_face_token_id = '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'\n","login(hugging_face_token_id)\n","\n","\n","# loading the models  (Whisper for speech) (Llama 2 for text)\n","\n","whisper_processor = WhisperProcessor.from_pretrained(\"openai/whisper-base\")\n","whisper_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-base\")\n","\n","llama_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n","llama_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n","\n","tts_engine = pyttsx3.init()\n","recognizer = sr.Recognizer()"],"metadata":{"id":"pTfL77_8cIGg","colab":{"base_uri":"https://localhost:8080/","height":140,"referenced_widgets":["0231bc74253642d9bbd1d48886efdec4","e033349c8b244f6ca8c0e3a7a148622c","566080d5e93a4bd39f13550dc025410b","789ced0a5f7b4cd79ed7c71bcff3ee7b","a0c22217f30347fcb7a9ab88aed9905d","57cc677d8b2d486daa9aa173be6f1402","3328c7ee8b2b48c685b952be234e8049","6c641ddc7d3549879db5e2551baa6e7a","088042b421214b7782d7052d8c4dc955","e23da6505ce640568d21c259ef46acd8","4dacb5592cd142c9b405d269113fe116"]},"outputId":"2d2ec6eb-8fc2-4388-ef9d-6ae59170ed33"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Token is valid (permission: fineGrained).\n","Your token has been saved in your configured git credential helpers (store).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0231bc74253642d9bbd1d48886efdec4"}},"metadata":{}}]},{"cell_type":"code","source":["def recognize_speech_microphone():  # recognize from microphone\n","    with sr.Microphone() as source:\n","        recognizer.adjust_for_ambient_noise(source)\n","        print(\"Listening...\")\n","        audio = recognizer.listen(source, timeout=5)\n","        audio_data = audio.get_wav_data()\n","        inputs = whisper_processor(audio_data, return_tensors=\"pt\", sampling_rate=16000)\n","        outputs = whisper_model.generate(inputs[\"input_ids\"])\n","        text = whisper_processor.decode(outputs[0], skip_special_tokens=True)\n","        print(f\"Recognized Text: {text}\")\n","        return text"],"metadata":{"id":"J-dDqturcIEk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def recognize_speech_webcam(): # recognize from webcam\n","    cap = cv2.VideoCapture(0)\n","\n","    while True:\n","        ret, frame = cap.read()\n","        if not ret:\n","            print(\"Failed to capture video.\")\n","            break\n","\n","        cv2.imshow(\"Webcam\", frame)\n","\n","        if cv2.waitKey(1) & 0xFF == ord('q'):\n","            with sr.Microphone() as source:\n","                print(\"Listening...\")\n","                audio = recognizer.listen(source, timeout=5)\n","                audio_data = audio.get_wav_data()\n","                inputs = whisper_processor(audio_data, return_tensors=\"pt\", sampling_rate=16000)\n","                outputs = whisper_model.generate(inputs[\"input_ids\"])\n","                text = whisper_processor.decode(outputs[0], skip_special_tokens=True)\n","                print(f\"Recognized Text: {text}\")\n","                cap.release()\n","                cv2.destroyAllWindows()\n","                return text\n","\n","    cap.release()\n","    cv2.destroyAllWindows()"],"metadata":{"id":"UboZ0BmKkWB7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def recognize_speech_text_input():\n","    text = input(\"Enter your text: \")\n","    return text"],"metadata":{"id":"bJ7-OvZjkV-j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_response(input_text):\n","    inputs = llama_tokenizer(input_text, return_tensors=\"pt\")\n","    outputs = llama_model.generate(inputs[\"input_ids\"])\n","    response_text = llama_tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    print(f\"Generated Response: {response_text}\")\n","    return response_text"],"metadata":{"id":"YjF5lmGpkV79"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def speak_text(text):\n","    tts_engine.say(text)\n","    tts_engine.runAndWait()"],"metadata":{"id":"5uYOfKi8kV5n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def main():\n","    print(\"Welcome to the Speech-to-Speech Application!\")\n","    print(\"Select input method:\")\n","    print(\"1: Microphone\")\n","    print(\"2: Webcam\")\n","    print(\"3: Text Input\")\n","\n","    choice = input(\"Enter the number of your choice: \")\n","\n","    if choice == \"1\":\n","        recognize_speech = recognize_speech_microphone\n","    elif choice == \"2\":\n","        recognize_speech = recognize_speech_webcam\n","    elif choice == \"3\":\n","        recognize_speech = recognize_speech_text_input\n","    else:\n","        print(\"Invalid choice!\")\n","        return\n","\n","    print(\"Starting the speech-to-speech application...\")\n","\n","    while True:\n","        spoken_text = recognize_speech()\n","        if not spoken_text:\n","            continue\n","\n","        response_text = generate_response(spoken_text)\n","        speak_text(response_text)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":847},"id":"9op5arX5kV29","outputId":"5405af24-1ad0-4ee0-f7f3-3a7bc516d78d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Select input method:\n","1: Microphone\n","2: Webcam\n","3: Text Input\n","Enter the number of your choice: 3\n","Starting the speech-to-speech application...\n","Enter your text: where is tajmahal?\n","Generated Response: where is tajmahal?\n","\n","The Taj Mahal is located in Agra, India. It is situated on the southern bank of the Yamuna River, and is considered one of the most beautiful examples of Mughal architecture in India. The Taj Mahal was built in the 17th century by Mughal Emperor Shah Jahan as a mausoleum for his wife, Mumtaz Mahal, who died during childbirth in 1631. The monument is made of white marble and features intricate inlay work of precious stones, including jasper, jade, and turquoise. It is considered one of the Seven Wonders of the World and is a UNESCO World Heritage Site.\n","Enter your text: IT means\n","Generated Response: IT means Information Technology. IT is a broad field that combines computer science, computer engineering, and other areas to design, develop, and manage computer systems and technology. IT professionals work in a variety of settings, including businesses, government agencies, and educational institutions, and may specialize in areas such as software development, network administration, cybersecurity, data analytics, and more.\n","\n","Some common job roles in IT include:\n","\n","1. Software Developer: Designs, develops, and tests software programs using various programming languages and technologies.\n","2. Network Administrator: Installs, maintains, and troubleshoots computer networks, including local area networks (LANs), wide area networks (WANs), and the Internet.\n","3. Cybersecurity Specialist: Protects computer systems and networks from cyber threats by implementing security measures, monitoring systems for potential breaches, and responding to incidents.\n","4. Data Analyst: Collects, organizes, and analyzes data to help organizations make informed decisions.\n","5. IT Project Manager: Oversees the planning, execution, and delivery of IT projects, ensuring they are completed on time, within budget, and to the satisfaction of stakeholders.\n","6. Technical Support Specialist: Provides assistance and support to users of computer systems and technology, troubleshooting problems and answering questions to help them get back to work.\n","7. Database Administrator: Designs, implements, and maintains databases for organizations, ensuring they are secure, efficient, and scalable.\n","8. Artificial Intelligence/Machine Learning Engineer: Develops and implements artificial intelligence and machine learning solutions for organizations, including natural language processing, computer vision, and predictive analytics.\n","9. Cloud Computing Engineer: Designs, builds, and manages cloud computing systems for organizations, including infrastructure as a service (IaaS), platform as a service (PaaS), and software as a service (SaaS).\n","10. IT Consultant: Provides advice and guidance to organizations on how to best use technology to achieve their business goals, including evaluating existing systems, identifying areas for improvement, and implementing new technologies.\n","\n","These are just a few examples of the many job roles available in IT. As technology continues to evolve and advance, new job roles and specialties are emerging all the time.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"Interrupted by user","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-45cf59f2fafd>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-25-45cf59f2fafd>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Step 1: Capture and recognize speech\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mspoken_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecognize_speech\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mspoken_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-a4db62a83519>\u001b[0m in \u001b[0;36mrecognize_speech_text_input\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Step 7: Define the function for text input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecognize_speech_text_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your text: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}]},{"cell_type":"code","source":[],"metadata":{"id":"HEc8T6qnkV0x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"R8UjkCRycICT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bKbD2_4HcIAE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Ngy3Ia8ccH93"},"execution_count":null,"outputs":[]}]}